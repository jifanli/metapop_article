%\documentclass[12pt]{article}
\documentclass[11pt]{article} \usepackage{fullpage}
\pdfoutput=1

\input{header}
\newcommand\stdError[1]{}
%\newcommand\stdError[1]{{\small(#1)}} 
\newcommand\includeRates[1]{}


%% \newcommand\arxiv[2]{#1}  %% for arxiv version
\newcommand\arxiv[2]{#2}  %% suppressing arxiv formatting

<<setup,echo=F,message=F,cache=F>>=
# computational intensity, i, also known as run level
i <- 3
library(metapoppkg)
library(foreach)
library(doParallel)
library(doRNG)
library(tidyverse)
library(patchwork)

Ncities <- ncol(metapoppkg::incidence) - 1 # first column is date
U <- switch(i,20,Ncities,Ncities)
cores <-  as.numeric(Sys.getenv('SLURM_NTASKS_PER_NODE', unset=NA))
if(is.na(cores)) cores <- detectCores()
registerDoParallel(cores)

ci_c <- readRDS("ci_c.rds")  # generated by si/si.Rnw
ci_uc <- readRDS("ci_uc.rds") # generated by si/si.Rnw

library(knitr)
opts_knit$set(concordance=TRUE)
opts_chunk$set(
  # cache=FALSE,
  cache=TRUE,   ## caution: use cache=TRUE only when making text edits
  progress=TRUE,
  prompt=TRUE,
  highlight=FALSE,
  tidy=TRUE,
  tidy.opts=list(
    keep.blank.line=FALSE
  ),
  comment="",
#  warning=FALSE,
#  message=FALSE,
  error=TRUE,
  echo=FALSE,
  strip.white=TRUE,
  results="markup",
  fig.path="figure/",
  fig.lp="fig:",
  fig.align="center",
  fig.show="asis",
  dev="png",
  dpi=300,
  dev.args=list(
    bg="transparent",
    pointsize=9
  )
)

@



\usepackage[sort&compress,numbers]{natbib}

\title{\myTitle}

\author
{Jifan Li,$^{1}$ Edward L. Ionides,$^{2\ast}$ Aaron A. King$^3$, Mercedes Pascual$^4$, Ning Ning$^{1\ast}$\\
\\
\normalsize{$^{1}$Department of Statistics, Texas A\&M University}
\\
\normalsize{$^{2}$Department of Statistics, University of Michigan}
\\
\normalsize{$^{3}$Department of Ecology \& Evolutionary Biology, University of Michigan}
\\
\normalsize{$^{4}$Department of Environmental Studies, New York University}
\\
\normalsize{$^\ast$To whom correspondence should be addressed; E-mail: ionides@umich.edu, patning@tamu.edu}
}

\date{}

%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



\begin{document} 


% Double-space the manuscript.
%\baselineskip24pt

\maketitle 

\begin{abstract}
Mathematical models in ecology and epidemiology must be consistent with observed data in order to generate reliable knowledge and evidence-based policy. Metapopulation systems, which consist of a network of connected sub-populations, pose technical challenges in statistical inference due to nonlinear, stochastic interactions. Numerical difficulties encountered in conducting inference can obstruct the core scientific questions concerning the link between the mathematical models and the data. Recently, an algorithm has been developed which enables effective likelihood-based inference for the high-dimensional partially observed stochastic dynamic models arising in metapopulation systems. The COVID-19 pandemic provides a situation where mathematical models and their policy implications were widely visible, and we use the new inferential technology to revisit an influential metapopulation model used to inform basic epidemiological understanding early in the pandemic. Our methods support self-critical data analysis, enabling us to identify and address model limitations, and leading to a new model with substantially improved statistical fit and parameter identifiability. Our results suggest that the lockdown initiated on January 23, 2020 in China was more effective than previously thought. We proceed to recommend statistical analysis standards for future metapopulation system modeling.
\end{abstract}

\section*{Introduction}
\label{sec:intro}

Biological populations may be structured into a collection of densely-populated communities separated by sparsely populated regions.
The network of communities, which may be cities in a human context, comprise a metapopulation.
Motivation for metapopulation modeling arises when some essential feature of the population dynamics cannot be understood from looking at a single location.
Dynamics of persistence through local extinctions and reintroductions have been extensively studied in ecology \cite{hanski98,mackenzie09}.
In epidemiology, metapopulation dynamics can be a barrier to the regional elimination and eventual eradication of a pathogen, and may determine the successful invasion of a new pathogen or a new strain of an existing pathogen \cite{metcalf21}.
In other situations, spatiotemporal dynamics may be an unavoidable component of the system under study without being the focus of the investigation \cite{zhang22,wheeler23}.

Mathematical models for biological systems are also used to inform public policy, despite delicate issues in their implementation and interpretation \cite{saltelli20}.
Indeed, it can be practically impossible to make sense of the nonlinear stochastic interactions driving biological dynamics without representing them via a model \cite{mccabe21,lofgren14}.
However. both operational and conceptual difficulties arise when developing these models.
Operationally, we seek to fit complex models using statistically valid, reproducible and transparent methods.
Conceptual difficulties arise when drawing causal conclusions from fitting models to observational data, giving rise to opportunities for incorrect conclusions due to missing variables or other forms of model misspecification.
A model assimilated to data guarantees that assumptions have been framed in a way consistent with certain facts, and evidence for predictive skill can support the value of the model construction.

A recent growth in the study of metapopulation dynamics has been driven partly by the COVID-19 pandemic \cite{li20,wu20,wang22,prieto22,cascante-vega22,pizzuti20,alleman21,yang21,engebretsen23} and in part by methodological advances facilitating the fitting of metapopulation models to spatiotemporal data.
Until the start of this millenium, developing dynamic models with both statistical and scientific justification was a longstanding open problem for even a single community \cite{bjornstad01}.
Over the past two decades, new algorithms \cite{ionides06,toni09,andrieu10,ionides15} and software \cite{king16,kristensen16,devalpine17}, together with ever-increasing computational resources, have enabled routine inference for low-dimensional nonlinear partially observed stochastic dynamic systems.
However, fundamental algorithmic scalability issues known as the ``curse of dimensionality'' lead to difficulties with the high-dimensional systems arising in metapopulation inference.
These issues are clearest for Monte Carlo techniques based on importance sampling \cite{bengtsson08} but are also evident in the need for variational approximations for large Monte Carlo Markov Chain (MCMC) calculations \cite{blei17}. 
Thus, data analysis for metapopulation models has lagged behind the analysis of low-dimensional time series data for biological dynamics.
Recent developments enable this gap to be closed, as we demonstrate via a reanalysis of COVID-19, viewed from the context of the ability to drawm evidence-based scientific conclusions about the dynamics of the emerging pandemic in January and February 2020.

Biological systems are characterized by nonlinear stochastic dynamics together with incomplete and noisy measurements  \cite{bjornstad01}.
We therefore focus on the class of partially observed Markov process (POMP) models \cite{breto09}, acknowledging that deterministic models can be conceptually useful but are problematic as statistical explanations of noisy systems \cite{king15,wheeler23}.
The Markov property asserts that the dynamic process has no memory conditional on its current state, which is algorithmically convenient while being scientifically nonrestrictive since we can choose what to include in the state.
Metapopulation models consider a multivariate system state at each location and so we require methods tailored for high-dimensional POMP models.
Simplifications arise if models and data are limited to binary presence-absence, or a small discrete set of values at each location \cite{mackenzie09}, but we are concerned with situations where time series of abundance data are available, such as case reports for infectious diseases.
We focus on two inferential approaches for high-dimensional POMP models, the block particle filter (BPF) and the ensemble Kalman filter (EnKF).
Other alternatives are reviewed in Supplementary Sec.~{\suppSecReview}.

EnKF was developed in the context of massive geophysical models.
It combines an ensemble representation of the latent state with a computationally efficient update rule inspired by the scalable linear Kalman filter, providing an approach with excellent scalability \cite{evensen09book,evensen22}.
For biological systems, EnKF was first demonstrated as a computationally convenient tool for compartment models at a single location \cite{shaman12,yang14}.
Subsequently, it has been applied for epidemiological metapopulation inference \cite{li20,kramer20-plos-cb}.
However, the linearization in the EnKF filter update rule can be problematic for highly nonlinear systems \cite{evensen22,ionides23-jasa}.
Further, a linear update rule is not appropriate for small, discrete populations unless EnKF is embedded within a MCMC algorithm \cite{katzfuss19}.
By contrast, particle filter methods \cite{doucet11} avoid linearization and are directly applicable to discrete and continuous latent states.

For low-dimensional systems, particle filter methods are broadly applicable; they permit consideration of arbitrary nonlinear dynamics and require the model to be specified only via a simulator \cite{breto09,king16}.
Particle filters enable statistically efficient use of data, since they provide an evaluation of the likelihood function required for Bayesian or likelihood-based inference, with approximation resulting only from finite Monte Carlo effort.
For high-dimensional systems, scalability considerations demand further approximations since particle filters suffer acutely from the ``curse of dimensionality'' \cite{bengtsson08}.
The BPF algorithm modifies the particle filter to achieve scalability by carrying out local resampling on spatial neighborhoods known as blocks.
This avoids the linear update rule used by EnKF \cite{rebeschini15}.
It is an empirical question whether the different approximations inherent in EnKF and BPF are successful on metapopulation models, with prior evidence favoring BPF \cite{ionides23-jasa}.
In the following example, we demonstrate that BPF can be effective for a practical metapopulation data analysis.
We show that the resulting likelihood-based inference framework provides opportunities for model criticism, leading to rigorous assessment of model fit and improved advice on public policy decisions.

\section*{Metapopulation analysis of COVID-19 spread in China}
\label{sec:covid}

We reconsider the influential analysis of COVID-19 from early in the pandemic by Li et al. \cite{li20}.
This analysis provided estimates of transmission parameters and the effect of the lockdown in China using the limited data available at the time.
Other teams have fitted models to address similar questions \cite{kraemer20,yang21,brett23} but the study by \cite{li20} is distinctive for fitting a stochastic mechanistic metapopulation model to extensive spatiotemporal data.
The results were published in May, 2020, based on reported cases from January 10 to February 8 of that year.
The state-of-the-art spatiotemporal analysis was possible on an urgent timescale because the team of researchers had developed their methodology in a sequence of previous situations \cite{shaman12,yang14,yang15,pei18}.
The paper is written with attention to reproducibility, and the main results are strengthened by various supporting analyses in an extensive supplement.
While examining the points mentioned above, we have identified various limitations that could have been mitigated by adhering to the aforementioned recommendations.
Our goal is not to criticize any specific paper, but rather to build on the timely analysis of \cite{li20} to demonstrate how recently developed techniques provide possibilities to carry out improved data analysis in future.

\usetikzlibrary{positioning}
\usetikzlibrary {arrows.meta}
\usetikzlibrary{shapes.geometric}

\begin{figure}
\begin{center}
%%%%% SEAIR diagram
\resizebox{!}{6cm}{
\begin{tikzpicture}[
  square/.style={rectangle, draw=black, minimum width=0.8cm, minimum height=0.8cm, rounded corners=.1cm, fill=blue!8},
  travel/.style={circle, draw=black, minimum width=0.85cm, minimum height=0.8cm, fill=green!8},
  report/.style={shape=regular polygon, regular polygon sides=8, draw, fill=red!8,minimum size=0.9cm,inner sep=0cm},
  bendy/.style={bend left=25},
  >/.style={shorten >=0.25mm}, % redefine arrow to stop short of node
  >/.tip={Stealth[length=1.5mm,width=1.5mm]} % redefine arrow style
]
\tikzset{>={}}; % this is needed to implement the arrow redefinition
\tikzset{every path/.style={line width=0.8 pt}}

\draw[rounded corners, green, thick] (-1.2, 1) rectangle (5.2, 2.5) {};
\draw[rounded corners, blue, thick] (-1.2, -2.4) rectangle (7.7, 0.7) {};
\draw[rounded corners, red, thick] (3.75, -4.15) rectangle (10.2, -2.85) {};
\node (between) at (5.4,2.3) [green, anchor=north west, font=\large] {Travel between cities};
\node (within) at (7.9,0.5) [blue, anchor=north west, font=\large] {Disease dynamics within cities};
\node (report) at (10.4,-3.05) [red, anchor=north west, font=\large] {Reported cases};

\node (S) at (-0.5,0) [square] {S$_u$};
\node (E) at (2,0) [square] {E$_u$};
\node (A) at (4.5,0) [square] {A$_u$};
\node (I) at (4.5,-1.75) [square] {I$_u$};
\node (R) at (7,0) [square] {R$_u$};

\node (T1) at (-0.5,1.75) [travel] {T};
\node (T2) at (2,1.75) [travel] {T};
\node (T3) at (4.5,1.75) [travel] {T};

\node (Ca) at (4.5,-3.5) [report] {C$^a_u$};
\node (Cb) at (7,-3.5) [report] {C$^b_u$};
\node (C) at (9.5,-3.5) [report] {C$_u$};

\node (V1) at (2.5,-1.75) {};
\node (V2) at (3,-3.5) {};
\draw [->] (E) -- (Ca -| V2) -- (Ca);
\draw [->] (I -| V1) -- (I);

\draw [->] (S) -- (E);
\draw [->] (A) -- (R);

\draw [->] (Ca) -- (Cb);
\draw [->] (Cb) -- (C);

\draw [->] (I.east) -- (R);
\draw [->] (E) -- (A);

\draw [->, bendy] (S) to (T1);
\draw [->, bendy] (T1) to (S);

\draw [->, bendy] (E) to (T2);
\draw [->, bendy] (T2) to (E);

\draw [->, bendy] (A) to (T3);
\draw [->, bendy] (T3) to (A);

\end{tikzpicture}
}
\end{center}
\vspace{-5mm}
\caption{A flow diagram for the SEAIR metapopulation model.
Each individual in city $u$ is a member of exactly one of the square blue compartments.
Individuals entering the reportable infectious compartment, $\mathrm{I}_u$ for city $u$, are simultaneously included in the delayed reporting process compartment, $\mathrm{C^a_u}$.
Upon arrival at the final reporting compartment, $\mathrm{C}_u$, the individual is included in the case report for city $u$.
Individuals in $\mathrm{A}_u$ are not reportable and transmit at a reduced rate.
Movement of individuals between cities occurs by transport to and from a transport compartment, $\mathrm{T}$.
The number of individuals moving between each pair of cities is based on 2018 data from Tencent.
Movement is modeled only for susceptible, exposed, and undetected infections.}\label{fig:flow_diagram}
\end{figure}

For our metapopulation system, the sub-populations are 373 provincial cities in China (meaning cities with administrative responsibility for an entire region) and the data are daily reported COVID-19 cases. 
COVID-19 dynamics are represented by a Susceptible Exposed Asymptomatic Infectious Recovered (SEAIR) epidemic model. 
Questions of urgent interest early in the pandemic include the relative transmissibility of reported to unreported cases, the fraction of unreported cases, and the effect on transmission of movement restrictions imposed on and around January 23 \cite{li20}.
The model structure is illustrated by the flow diagram in Fig.~\ref{fig:flow_diagram}.
The Methods section provides additional description, with Eq.~(\ref{eq:muSE}) giving the modeled rate at which susceptible individuals become infected.
The complete model specification and estimated parameter values are in Supplementary Sec.~{\suppSecOurModel}.

We consider different model implementations within this structure.
Our starting point is model {\LiMobility} which is based on the model of \cite{li20} and is described in Supplementary Sec.~{\suppSecLiModel}.
We consider the full dataset, from January 10 to February 8, with transmission parameters re-estimated following the lockdown on January 23; these correspond to the periods~1 (January 10 to January 22) and 3 (January 24 to February 8) of \cite{li20}.
Some minor differences between {\LiMobility} and \citep{li20} were introduced to enable us to place their model within the general metapopulation framework of spatiotemporal partially observed  continuous-time Markov processs described by \citep{ionides23-jasa}.
Despite these modifications, simulations from {\LiMobility}, using the parameters of \citep{li20}, closely match simulations from the code provided by \cite{li20} (Supplementary Sec.~\suppSecLiModel).
However, inspection of the mobility data reveals that some small cities have no recorded incoming travelers, and therefore no possibility of a SARS-CoV2 introduction within {\LiMobility} (or the model of \cite{li20}) (Supplementary Sec.~\suppSecMobility).
This minor limitation formally results in a likelihood of zero for {\LiMobility} (i.e., it is impossible for the simulation model to reproduce the observed spatiotemporal dataset), and hence a log-likelihood of $-\infty$.

<<benchmarks,echo=F>>=
benchdir <- paste0("benchmark_",i,"/")
if (!dir.exists(benchdir)) dir.create(benchdir)
stew(file=paste0(benchdir,"iid.rda"),{
  iid_negloglik <- function(theta,x) {
    z <- 0
    for(u in 1:ncol(x)) z <- z - sum(dnbinom(x[,u],
      # variance is mu + mu^2/size
      size=exp(theta["log.size"]),
      mu=exp(theta[u]),log=T))
    return(z)
  }

  if(0) { # currently not used in the ms
    # January 10-23 is observation 1-14
    x1 <- incidence[1:14,2:(U+1)]
    theta1=c(log.mu=log(colMeans(x1)+0.01),log.size=log(2))
    iid_mle1 <- optim(theta1,iid_negloglik,x=x1)

    # January 10- February 3 is observation 1-25
    x2 <- incidence[1:25,2:(U+1)]
    theta2=c(log.mu=log(colMeans(x2)+0.01),log.size=log(2))
    iid_mle2 <- optim(theta2,iid_negloglik,x=x2)
  }
  
  # January 10- February 8 is observation 1-30
  x3 <- incidence[1:30,2:(U+1)]
  theta3=c(log.mu=log(colMeans(x3)+0.01),log.size=log(2))
  iid_mle3 <- optim(theta3,iid_negloglik,x=x3)

})

stew(file=paste0(benchdir,"ar.rda"),{
  ar_negloglik <- function(theta,x) {
    z <- 0
    for(u in 1:ncol(x)) z <- z - sum(dnbinom(x[,u],
      size=exp(theta["log.size"]),
      mu=exp(theta[u])+exp(theta["log.phi"])*c(0,x[1:(nrow(x)-1),u]),log=T))
    return(z)
  }  

  if(0) { # currently not used in the ms
    ar_theta1=c(log.mu=log(0.5*colMeans(x1)+0.01),log.size=log(2),log.phi=log(0.8))
    ar_mle1 <- optim(ar_theta1,ar_negloglik,x=x1)

    ar_theta2=c(log.mu=log(0.5*colMeans(x2)+0.01),log.size=log(2),log.phi=log(0.8))
    ar_mle2 <- optim(ar_theta2,ar_negloglik,x=x2)
  }
  
  ar_theta3=c(log.mu=log(0.5*colMeans(x3)+0.01),log.size=log(2),log.phi=log(0.8))
  ar_mle3 <- optim(ar_theta3,ar_negloglik,x=x3)

})
@

<<loglik-M5,echo=F>>=
#out3 <- readRDS("j6/out_3/j6.rds")
#out3 <- readRDS("l7/out_3/l7.rds")
out3 <- readRDS("l8/out_3/l8.rds")
mle3 <- unlist(out3[which.max(out3$logLik),-c(1,2)])
lik3 <- unlist(out3[which.max(out3$logLik),c(1,2)])
@

<<loglik-M6,echo=F>>=
#out6 <- readRDS("o5/out_3/o5.rds")
#out6 <- readRDS("s4/out_3/s4.rds")
out6 <- readRDS("s5/out_3/s5.rds")
mle6 <- unlist(out6[which.max(out6$logLik),-c(1,2)])
lik6 <- unlist(out6[which.max(out6$logLik),c(1,2)])
@

<<loglik-M2,echo=F>>=
loglikdir <- paste0("loglik_",i,"/")
if (!dir.exists(loglikdir)) dir.create(loglikdir)
if(0){ # for testing
  library(metapoppkg)
  library(doParallel)
  library(doRNG)
  cores <-  as.numeric(Sys.getenv('SLURM_NTASKS_PER_NODE', unset = NA))
  if(is.na(cores)) cores <- detectCores()
  registerDoParallel(cores)
}
registerDoRNG(234)

li20_rinit <- Csnippet("
    double *S = &S1;
    double *E = &E1;
    double *A = &A1;
    double *I = &I1;
    double *Ca = &Ca1;
    double *Cb = &Cb1;
    double *C = &C1;
    const double *pop = &pop1;
    int u;

    for (u = 0; u < U; u++) {
      E[u] = 0;
      A[u] = 0;
      I[u] = 0;
      Ca[u] = 0;
      Cb[u] = 0;
      C[u] = 0;
      S[u] = nearbyint(pop[u]);
    }
      
    E[0]=nearbyint(2000*runif(0,1));
    A[0]=nearbyint(2000*runif(0,1));
    for (u = 1; u < U; u++) {
      E[u]=nearbyint(3*mob[14*u][0]*E[0]/(pop[0]));
      A[u]=nearbyint(3*mob[14*u][0]*2000*A[0]/(pop[0]));
    }
")
li20_dunit_measure <- Csnippet("
      double AA,BB;
      double m = C;
      double v = m*m/4 > 4 ? m*m/4 : 4;

      if (cases > m) {
          AA = pnorm(cases-0.5,m,sqrt(v),0,1);
          BB = pnorm(cases+0.5,m,sqrt(v),0,1);
          lik = AA + log(1-exp(BB-AA));
      } else if (cases > 0) {
          AA = pnorm(cases+0.5,m,sqrt(v),1,1);
          BB = pnorm(cases-0.5,m,sqrt(v),1,1);
          lik = AA + log(1-exp(BB-AA));
      } else {
        lik = pnorm(cases+0.5,m,sqrt(v),1,1);
      }
      if(!give_log) lik = exp(lik);
")

## to rebuild the global C definition for mobility, we need to define mob in the recompiled code for rinit
  mob_modify_factor <- 20
  days <- 30

## start: lines 121-136 of metapoppkg/R/li23.R #######################################
  mobi <- metapoppkg::mobility+metapoppkg::v_by_g_day*mob_modify_factor
  popu <- metapoppkg::population[1:days+rep((0:372)*30,each=days),]
  incidence <- metapoppkg::incidence

  # choose the cities with largest number of cases
  index <- order(colSums(incidence)[-1], decreasing = T)[1:U]
  incidence <- incidence[1:days,c(1,index+1)]
  
  index_mob <- rep(index*14-13,each=14)+rep(0:13,U)
  mobi <- mobi[index_mob,index]
  popu <- popu[rep(index*days-days+1,each=days)+rep(0:(days-1),U),]

  to_C_array <- function(v)paste0("{",paste0(v,collapse=","),"}")
  mobi_rows <- apply(mobi,1,to_C_array)
  mobi_array <- to_C_array(mobi_rows)
  mobi_C <- Csnippet(paste0("const double mob[",U*14,"][",U,"] = ",mobi_array,"; "))
## end: lines 121-136 of metapoppkg/R/li23.R #######################################

model2filters <- bake(file=paste0(loglikdir,"model2.rds"),{
  M2_tmp <- li23(U=U, mob_modify_factor=20,for_ibpf=F,version="li20period3")
  M2 <- spatPomp(M2_tmp,dunit_measure=li20_dunit_measure,rinit=li20_rinit,
    unit_statenames = c('S','E','A','I','Ca','Cb','C'),
    globals = mobi_C
  )
  foreach(k=1:switch(i,2,5,20),.combine=c) %dopar% {
    logLik(bpfilter(M2,block_size=1,Np=switch(i,10,200,2000)))
  }
})
M2_loglik <- logmeanexp(model2filters,se=T)
@

\begin{table}[ht]
\small
\begin{tabular}{c|rr|l}
Model & loglik & df & description
\\
\hline
{\LiMobility} &
  $-\infty$ & 10 &
  SEAIR model using the parameter values and mobility data of \cite{li20}
\\
{\LiParams} &
  \Sexpr{metapoppkg::myround(mean(M2_loglik['est']),1)}\stdError{\Sexpr{metapoppkg::myround(M2_loglik['se'],1)}}& 10 &
  Adjusted mobility and measurement in {\LiMobility}
\\
{\BenchmarkIID} &
  \Sexpr{metapoppkg::myround(-iid_mle3$value,1)}  & \Sexpr{U+1} &
  Independent identically distributed negative binomial
\\
{\BenchmarkAR} &
 \Sexpr{metapoppkg::myround(-ar_mle3$value,1)}  & \Sexpr{U+2} &
  Autoregressive negative binomial
\\
{\RevisedModelUnconstrained} &
  \Sexpr{metapoppkg::myround(lik3["logLik"],1)}\stdError{\Sexpr{metapoppkg::myround(lik3["logLik_se"],1)}}&
  12 &
  Adding overdispersed dynamics to {\LiParams} and refitting
\\
{\RevisedModelConstrained} &
  \Sexpr{metapoppkg::myround(lik6["logLik"],1)}\stdError{\Sexpr{metapoppkg::myround(lik6["logLik_se"],1)}}&
  10 &
  Latent and infectious durations unchanged by lockdown in {\RevisedModelUnconstrained}.
\\

\hline
\end{tabular}
\caption{Model comparisons by log-likelihood, evaluated by a block particle filter. The degrees of freedom (df) is the number of estimated parameters. 
}
\label{tab:loglik}
\end{table}

We addressed the problematic mobility data in {\LiMobility} by adding some additional transportation based on a gravity movement model, as described in Supplementary Sec.~{\suppSecMobility}, giving rise to model~{\LiParams}.
We implemented an additional adjustment between models {\LiMobility} and {\LiParams} to align the measurement model with the ensemble Kalman filter (EnKF) inference method presented by \cite{li20}.
That EnKF implementation involved specifying a quantity called the observation error variance, defined as a function of the observed cases, to quantify the uncertainty in the measurements.
Within the POMP specification, the measurement variance can depend on the latent state but not directly on the observed data.
To interpret the choice of EnKF observation variance within the POMP framework, we specified the measurement model for~{\LiParams} to have equivalent scaling to the choice of \citep{li20}, but with dependence on the reported cases replaced by dependence on the modeled, but unobserved, exact case count.

Based on a comparison of various nonlinear spatiotemporal filters (Supplemtary Fig.~\suppFigFilterComparison) we evaluated the log-likelihood for {\LiParams} using a block particle filter (Table~\ref{tab:loglik}).
To account for model overfitting, the number of estimated parameters can be subtracted from the log-likelihood to obtain a comparison equivalent to Akaike's Information Criterion (AIC) \citep{burnham02}.
When the difference in log-likelihood is large compared to the difference in degrees of freedom, the ordering of statistical goodness-of-fit is clear without presenting formal statistical hypothesis tests.

To find out whether this log-likelihood value suggests that the model is satisfactory, we compare it with two simple statistical models:
{\BenchmarkIID} simply models the daily case report for each city as an independent identically distributed (IID) negative binomial random variable; 
{\BenchmarkAR} adds an autoregressive component to {\BenchmarkIID} (see Supplemetary Sec.~\suppSecBenchmark).
We see from Table~\ref{tab:loglik} that both {\BenchmarkIID} and {\BenchmarkAR} outperform {\LiParams} by many units of log-likelihood.
Likelihood can properly be compared between different models for the same data, with statistical uncertainty in log-likelihood differences arising on the unit scale \citep{pawitan01}.
When the fit of a mechanistic model is inferior to a simple statistical model, we learn that the mechanistic model has room for improvement as a description of the data, but we do not immediately learn what the deficiency is.
The development of methods for formal statistical fitting of mechanistic models has led to increased understanding of the importance of appropriate modeling of over-dispersed variation in the stochastic dynamics \cite{he10,stocks20,whitehouse23}.
We therefore hypothesized that the fit of {\LiParams} could be improved by permitting additional dynamic noise.

A standard way to convert a deterministic model, constructed as a system of ordinary differential equations, into a stochastic model is to reinterpret the rates of the deterministic system as rates of a Markov chain \citep{keeling09}.
This places limits on the mean-variance relationship of the resulting stochastic model \citep{breto11}.
Models allowing greater variability that permitted by this construction are said to be over-dispersed.
We added multiplicative white noise to the transmission rate, following the approach of \citep{breto09,he10}, giving rise to model~{\RevisedModelUnconstrained}.
We fitted the model using an iterated block particle filter to maximize the likelihood \citep{ionides22,ning23}.
The block filter approximation has also proven helpful for spatiotemporal inference when using alternatives to particle filtering and alternatives to maximization by iterated filtering \cite{whitehouse23}.
In the current context, the block particle filter was found to be more effective for likelihood evaluation than a test suite of alternative filters including the ensemble Kalman filter (Supplementary Fig.~\suppFigFilterComparison).
The iterated block particle filter maximizes the block particle filter likelihood using an iterated filtering algorithm \citep{ionides15} adapted to the structure of a block particle filter.

Table~1 shows that model~{\RevisedModelUnconstrained} outperforms simple statistical benchmarks, obtaining a competitive likelihood with relatively few parameters.
From a statistical perspective, {\RevisedModelUnconstrained} is therefore an adequate statistical description of the data.
However, some parameters of {\RevisedModelUnconstrained} were weakly identified by the data, especially in the pre-lockdown time interval within which there were relatively few reported cases (Supplementary Sec.~\suppSecUnconstrained).
When the evidence about the model parameters in the data is weak, the ambiguity may be resolved by other, unmodeled and poorly understood, aspects of the data.
This risks leading to undesirable situations where substantial conclusions about questions of interest could be driven by the weaknesses of the model rather than its strengths.
In Supplementary Sec.~{\suppSecUnconstrained}, we show how the flexibility of {\RevisedModelUnconstrained} can be used to obtain a high likelihood via an unplausibly long estimated duration of infection during the pre-lockdown period, with the estimate suddenly reducing after lockdown.
 We resolved this issue by constraining the latent and infectious periods to be the same before and after lockdown, leading to model {\RevisedModelConstrained}.
 The additional constraints of {\RevisedModelConstrained} lead to a small loss of likelihood compared to {\RevisedModelUnconstrained}, but the fit remains competitive compared to the benchmark models, and the stronger identifiability facilitates the interpretation of estimated parameters.
Calculating the log-likelihood for each model in Table~\ref{tab:loglik} requires extensive computation to produce a single number which contains essentially all the information about the statistical fit of the model.
However, deeper investigation is required to understand what characteristics of the models and data causes the differences in these numbers, and the practical consequences of the numerical results.
As a starting point, Fig.~\ref{fig:panel_plot} plots the data next to simulations from models {\LiMobility} and {\RevisedModelConstrained}.
Visually, the comparison confirms {\RevisedModelConstrained} as a reasonable representation of the data.
Both {\LiMobility} and {\RevisedModelConstrained} overestimate cases before day 14, but the context of rapidly increasing awareness and growing diagnostic capabilities is hard to quantify.

<<panel_plot, message=FALSE, echo=FALSE,fig.width=8.5,fig.height=10,out.width="6.5in",fig.cap="Daily case report time series for 373 cities: (A) the real data; (B) a simulation from model {\\LiMobility}; (C) a simulation from model~{\\RevisedModelConstrained}. Within each panel, cities are ordered by population, largest on the bottom row.">>=
i <- 3
plotdir <- paste0("plot_",i,"/")
if (!dir.exists(plotdir)) dir.create(plotdir)
stew(file=paste0(plotdir,"panel.rda"),{
  U <-switch(i, 5,50,373)
  M6 <- li23v3(U=U)
  M6_sim <- simulate(M6,params=mle6,seed=4)
  M1 <- spatPomp(li23(U=U,version="li20period3",for_ibpf=F, mob_modify_factor=0),
    rmeasure=spatPomp_Csnippet(
      unit_statenames='C',
      code="
        double* cases=&cases1;
        int u;
        for (u = 0; u < U; u++) {
          if (C[u] > 0.0) {
            cases[u] = nearbyint(C[u]);
          } else {
            cases[u] = 0.0;
          }
        } 
      "
    )
  )
  coef(M1)["sigma_SE1"] <- 0
  M1_sim <- simulate(M1,seed=100)
})
panel_plot <- bake(file=paste0(plotdir,"panel2.rds"),{
  limit <- log10(max(c(obs(M6),obs(M6_sim),obs(M1_sim)))+1)
  M6_plot <- plot_li(M6_sim, U=U, limit=limit) + ggtitle(expression("(C) "~Model~M[6])) +
    ylab("City") +
    xlab("Day") +
    theme(legend.position = "bottom")
  M1_plot <- plot_li(M1_sim, U=U, limit=limit) + ggtitle(expression("(B) "~Model~M[1])) +
    ylab("City") +
    theme(legend.position = "none", axis.title.x=element_blank(),
      axis.ticks.x=element_blank(), axis.text.x=element_blank())
  data_plot <- plot_li(M6, U=U, limit=limit) + ggtitle(expression("(A) "~Data)) + 
    ylab("City") +
    theme(legend.position = "none", axis.title.x=element_blank(),
      axis.ticks.x=element_blank(), axis.text.x=element_blank())
  data_plot/M1_plot/M6_plot
})  
panel_plot
@

Parameter values for models~ {\LiMobility},~{\RevisedModelUnconstrained} and~{\RevisedModelConstrained} are reported in Supplementary Table~{\suppTableResults}.
Here, we discuss the estimated basic reproductive number (i.e., the expected number of secondary infections from one index case in a fully susceptible population), denoted by $\Rzero^{\before}$ and $\Rzero^{\after}$ before and after the January 23rd lockdown.
$\Rzero$ is calculated by the formula in Eq.~(\ref{eq:Rzero}).
Our estimates for model {\RevisedModelConstrained}, are $\Rzero^{\before}=\Sexpr{metapoppkg::myround(ci_c["R0_be", "mle"],2)}$ with confidence interval (CI) (\Sexpr{metapoppkg::myround(ci_c["R0_be", "ci1"],2)},\Sexpr{metapoppkg::myround(ci_c["R0_be", "ci2"],2)}) and $\Rzero^{\after}=\Sexpr{metapoppkg::myround(ci_c["R0_af","mle"],2)}$  with CI (\Sexpr{metapoppkg::myround(ci_c["R0_af", "ci1"],2)},\Sexpr{metapoppkg::myround(ci_c["R0_af","ci2"],2)}), where the estimates and their associated 95\% CIs obtained by profile likelihood (Supplementary Sec.~\suppSecInference).
This implies that the Chinese government non-pharmaceutical interventions instituted on and around January 23 reduced $\Rzero$ by a factor of $\Sexpr{metapoppkg::myround(ci_c["R0_be","mle"]/ci_c["R0_af","mle"],1)}$.
By contrast, the estimates of \cite{li20} are $\widetilde\Rzero^{\before}=2.38$  with CI $(2.03,2.77)$ and $\widetilde\Rzero^{\after}=0.98$  with CI $(0.83,1.16)$, implying reduction by a factor of $\Sexpr{metapoppkg::myround(2.38/0.98,1)}$.
For comparison, interventions implemented across a panel of 41 countries (34 European) were estimated to reduce $\Rzero$ by a factor of $\Sexpr{metapoppkg::myround(1/(1-0.77),1)}$  with CI $(\Sexpr{metapoppkg::myround(1/(1-0.65),1)},\Sexpr{metapoppkg::myround(1/(1-0.85),1)})$ \citep{brauner21}.
Our estimate for $\Rzero$ before lockdown is toward the high end of previous estimates based on data up to February 2020, reviewed by \citep{park20-jcm}.
An alternative metaopopulation analysis of the pre-lockdown China data, with a deterministic transmission model, obtained an $\Rzero$ estimate of 3.11  with CI  (2.39,4.13) \citep{read21}.
Our $\Rzero$ estimate is consistent with pre-lockdown estimates from other locations, such as New York city, for models that include asymptomatics \cite{subramanian21}.

The likelihood-based confidence intervals for {\RevisedModelConstrained} are narrower than the intervals from \cite{li20}.
However, {\RevisedModelConstrained} fits two fewer parameters than {\RevisedModelUnconstrained}, and the latter is more directly comparable to the model of \cite{li20}.
For {\RevisedModelUnconstrained}, the likelihood-based analysis leads to some wide confidence intervals, revealing the weakly identified parameters.

Our model inherits the property of \citep{li20} that infections arising during the pre-lockdown period will generally be reported during the lockdown, due to the reporting delay modeled as a distributed delay with a mean of 9 days pre-lockdown and 6 days post-lockdown.
Thus, the model is permitted to explain the data by inferring rapid, unreported spread prior to January 23.
Despite this shared constraint on the form of the model, conclusions of our analysis differ from \cite{li20}.
Beyond the estimates of $\Rzero$, a notable difference is that we find the estimated transmissibility of observed cases is close to that of unobserved cases, especially before lockdown (Supplementary Table~S1).

Not all models are equal, and we have demonstrated an approach which evaluates the extent to which the postulated models statistically explain the observed data. 
Our analysis cannot disprove the possibility of an alternative model which explains the data even better via an alternative model specification, perhaps leading to alternative conclusions.
Indeed, our methods are designed to facilitate others to develop and demostrate superiority to our own analysis when such advances are available.

If a mechanistic model has likelihood competitive with statistical benchmarks, it is anticipated to have simulations that are qualitatively comparable to the data.
Since the model specification is inevitably imperfect, and is accounted for in the model fitting by noise processes, we expect simulations from the fitted model to have somewhat more stochastic variation than the data.
By contrast, models which are structurally unable to provide sufficient variability to explain the data must give rise to simulations with too little stochasticity (as shown in Fig.~\ref{fig:panel_plot}).
Models that have simulations with implausibly little variability give rise to claims of excessive confidence about the uncertainty surrounding estimated parameters.
This phenomenon may be clearest when CIs are calculated using  parametric bootstrap approach, involving re-estimation of parameters using artificial datasets simulated from a fitted model.
However, it also applies for classical CI and Bayesian credible interval constructions.
Thus, CIs from mechanistic models that outperform statistical benchmarks are anticipated to be conservative, whereas CIs from models with insufficient variability to explain the data are generally anti-conservative.
Requiring model likelihoods to be comparable to statistical benchmarks therefore improves the credibility of uncertainty intervals as well as improving the accuracy of point estimates.

\section*{Discussion}
\label{sec:conclusion}

Advances in statistical methodology will drive an increase in the number of spatiotemporal models fitted to epidemiological data.
Our research demonstrates that techniques proven effective in low-dimensional systems, such as population dynamics at one or two locations, can be extended to address larger metapopulation systems.
This extension allows us to leverage well-established best practices from time series analysis, leading to a statistically principled approach. This approach enables us to identify and rectify model limitations that might otherwise remain undetected.
Failure to address these weaknesses can lead to issues of irreproducibility and the provision of suboptimal policy recommendations when developing models for complex dynamic systems \cite{saltelli20,ioannidis22}.
Principles of good data analysis for population dynamics are presumably similar to general principles of data science \cite{yu20} but require some adaptation to the specific situation.
Here, we build on \cite{saltelli20,ioannidis22,yu20}, by demonstrating the feasibility and desirability of metapopulation analysis meeting the specific set of criteria outlined below.


\begin{enumerate}

\item \label{point:i} {\bf Likelihood-based statistical inference}. A model, in conjunction with data, defines a likelihood function that quantifies the goodness of fit of the model and the data for each parameter value.
For mechanistic models, it is usually impossible to write down the likelihood explicitly, but it still exists implicitly.
Such methods extract all available information in the data about model parameters \cite{pawitan01}.
Log-likelihood is also a proper scoring rule for comparing probabilistic forecasts \cite{gneiting07} and therefore provides a sensitive objective tool for model selection and identification of model misspecification.
Whereas cross-validation and out-of-sample fit are standard benchmarks in machine learning settings \cite{yu20}, likelihood is better suited to situations with relatively small, spatiotemporally structured datasets.
Likelihood-based inference via particle filters has been considered inaccessible for metapopulation models due to the ``curse of dimensionality'' \cite{bengtsson08}.
However, block particle filter methods can be effective on metapopulation models, as demonstrated in this paper and previously \cite{ionides23-jasa,ning23,wheeler23}.
All high-dimensional nonlinear filters entail numerical approximation, and these can be assessed by comparing predictive skill (i.e., the estimated log-likelihood) between different filters.
The ensemble Kalman filter provides a suitable point of comparison, since it has excellent scalability properties, modest capability to handle nonlinearities, and has been demonstrated on various epidemiological systems \cite{shaman12,yang14,yang15,pei18,yang21,kramer20-plos-cb,cascante-vega22}.

\item \label{point:ii} {\bf Statistical benchmarks}.
The challenge of fitting intricate nonlinear models to extensive datasets makes it difficult for researchers to evaluate the limitations of their models and methods.
Readers also can struggle to determine whether the proposed model has been adequately tested.
It is therefore advisable to incorporate benchmarks for evaluating model performance in comparison to relatively simple statistical models \citep{he10}.
This approach helps determine whether complex models provide a satisfactory level of explanatory power.
In the first instance, these benchmarks can be applied to the entire dataset; subsequent analysis can focus on dissecting the contributions from various subsets of the data to gain a comprehensive understanding of which parts of the data drive the overall assessment.
The likelihood provides a suitable quantity for comparison between different models for the same data \cite{pawitan01}.
If we find a simple statistical model with a log-likelihood many units higher than a mechanistic model, we have discovered that the mechanistic model is unable to explain some substantial aspect of the data.
At the very least, this discrepancy should be identified and discussed.

\item \label{point:iii} {\bf Residual analysis}.
Introductory statistics classes, when covering linear regression, emphasize that a careful and complete data analysis involves examining deviations from the fitted model \cite{faraway14}.
This is typically achieved by plotting residuals, a suitably rescaled measure of disparities between each observation and its corresponding fitted value.
A relevant measure of residual in the current context is the {\it log-likelihood anomaly}, defined as the discrepancy between the mechanistic fit and a benchmark for components of the likelihood at each observation.
Supplementary Sec.~{\suppSecResiduals} describes how these tools were used for developing and evaluating model~{\RevisedModelConstrained}.

\item \label{point:vii} {\bf Uncertainty}.
Reliable conclusions should be robust to plausible variations in data, models, and algorithms \cite{yu20}.
Standard statistical methods provide measures of uncertainty, and the validity of these measures depends critically on the statistical validity of the model.
Appropriate modeling of overdispersion can be critical to accurate assessment of uncertainty for dynamic models \citep{breto09,he10,stocks20,whitehouse23}.

\item \label{point:viii} {\bf Reproducibility and extendability}.
Observational studies are not generally replicable in an experimental sense.
However,  the numerical conclusions should be readily reproducible from the observations.
A substantial part of the value of a computational model is that it permits {\it in silico} experimentation of the modeled system.
The authors should build and share a computational environment that not only reproduces published numbers but also facilitates future {\it in silico} experimentation.
Subsequent research should readily be able to challenge the assumptions of the model in light of subsequent data.
In practice, this requires that the scientists provide a free, open-source software environment within which the published analysis can readily be reproduced, modified and extended \citep{gentleman07,wheeler23}. 
Development of a principled data analysis environment assists the researchers to explore their own models and data, and this environment should be shared as part of the publication process.
In practice, this involves encapsulating data analysis within a software package that immerses the user in a documented environment where the models, methods and data used for the article can be readily be experimented with.
Trustworthy data analysis should be supported by unit testing and documentation, and the quality of this support should be one of the considerations in evaluation of the data analysis.
In other words, the article presenting the research should be part of a compendium \cite{gentleman07}.
The compendium for this article is comprised of the article source code, at \url{https://github.com/jifanli/metapop_article}, together with the software environment for the data analysis, provided by the R package at \url{https://github.com/jifanli/metapoppkg}.

\item \label{point:ix} {\bf Appropriate conclusions from observational data}.
In the absence of a randomized controlled experiment, the care required to move from a fitted model parameter to a causal claim is well known in linear regression analysis \cite{faraway14}.
The same principles apply to nonlinear dynamic metapopulation models: the model structure may be informed by prior scientific knowledge, and the model may statistically explain population-level data, yet observational data cannot readily rule out the possibility of alternative explanations.
A model may be called hypothetically causal when it is consistent with scientifically plausible causal mechanisms, but the model fitting process does not itself validate these assumptions---this is a common situation for metapopulation modeling.

\end{enumerate}

In conclusion, the study of metapopulation dynamics will continue to benefit from advances in algorithms, software, and data analysis methodologies.
The models should undergo critical scrutiny to delineate their strengths and weaknesses, following evaluation procedures such as we have described in this paper. 
With due care, these models can unearth limitations in existing knowledge, investigate hypotheses that may extend our knowledge, and furnish us with valuable predictive tools.

\section*{Methods}

\noindent {\it Data}.
COVID-19 case reports, city population counts, and the time-varying matrix of movement between cities, were taken from \citep{li20}.
Some erroneous numbers, revealed by our log-likelihood anomaly analysis, were subsequently modified as described in Supplementary Sec.~{\suppSecOurModel}.

\vspace{3mm}

\noindent {\it Model}.
All the mechanistic models under consideration have an SEAIR structure, as described in Figure~\ref{fig:flow_diagram}.
Supplementary Sec.~{\suppSecOurModel} provides a full mathematical representation of the SEAIR model.
Briefly, the force of infection on susceptible individuals for city $u$ due to symptomatic and asymptomatic individuals in city $u$ is given by
\begin{equation}
\label{eq:muSE}
\mu_{S_{u}E_{u}} = \beta S_{u}(t) \left(\frac{I_{u}(t)+ \relativeTransmission A_{u}(t)}{\pop_{u}(t)}\right) d\Gamma_{u}/dt,
\end{equation}
where $\beta$ is a transmission rate, $\relativeTransmission$ is the relative transmissibility of asymptomatic cases, and $\pop_u$ is the city population.
The Gamma white noise process, $d\Gamma_{u}/dt$, allows for stochastic variation in the transmission rate \cite{breto09}.
The rate at which individuals move between each pair of cities is defined by a time-varying matrix based on high-resolution Tencent data from 2018, as described in Supplementary Sec.~{\suppSecMobility}.
The basic reproductive number is given by
\begin{equation}
\label{eq:Rzero}
\Rzero=\big(\reportRate+(1-\reportRate)\relativeTransmission\big)\infectiousPeriod\beta,
\end{equation}
where $\infectiousPeriod$ is the mean infectious period and $\reportRate$ is the fraction of cases severe enough to be reported.


\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}[
  every node/.style={scale=0.85},
  square/.style={rectangle, draw=black, minimum width=5.5cm, minimum height=0.7cm, rounded corners=.1cm,font=\ttfamily},
  block/.style={rectangle, draw=black, minimum width=1.5cm, align=center, rounded corners=.1cm,font=\ttfamily},
  >/.style={shorten >=0.4mm}, % redefine arrow to stop short of node
  >/.tip={Stealth[length=2.5mm,width=1.5mm]} % redefine arrow style
]
\tikzset{>={}}; % this is needed to implement the arrow redefinition
  \node (initialize)   at (0,7.3)  [square] {Initialize model \& parameters};
  \node (perturb)    at (0,6) [square,fill=blue!8] {Perturb parameters};
  
  \node (predict)  at (0,4.7)  [square] {Predict:~stochastic dynamics};
  
  \node (reweight1) at (-3,3)  [block] {Reweight \\ Block 1};
  \node (reweight2) at (-1,3)  [block] {Reweight\\ Block 2};
  \node (reweight3) at (1,3) {\texttt{...}};
  \node (reweightK) at (3,3)  [block] {Reweight\\ Block K};

  \node (resample1) at (-3,1.5)  [block] {Resample\\state};
  \node (resample2) at (-1,1.5)  [block] {Resample\\ state};
  \node (resampleK) at (3,1.5)  [block] {Resample\\ state};

  \node (resample3) at (1,1) {\texttt{...}};

  \node (params1) at (-3,0.5)  [block, fill=blue!8] {Resample\\ params};
  \node (params2) at (-1,0.5)  [block, fill=blue!8] {Resample\\ params};
  \node (paramsK) at (3,0.5)  [block, fill=blue!8] {Resample\\ params};

  \node (recombine) at (0,-1.2)  [square] {Recombine};

  \node (N) at (5.5,3)  [draw,diamond,aspect=1.5] {\texttt{n=1:N}};
  \node (M) at (7.5,3)  [draw,diamond,aspect=1.5,fill=blue!8] {\texttt{m=1:M}};
  \node (mysouth) at (0,-1.8) {};

  \draw[->] (initialize.south) -- (perturb.north);
  \draw[->] (perturb.south) -- (predict.north);
  \draw[->] (predict) -- (reweight1.north);
  \draw[->] (predict) -- (reweight2.north);
  \draw[->] (predict) -- (reweightK.north);
  \draw[->] (reweight1) -- (resample1);
  \draw[->] (reweight2) -- (resample2);
  \draw[->] (reweightK) -- (resampleK);
  
  \draw[->] (params1.south) -- (recombine);
  \draw[->] (params2.south) -- (recombine);
  \draw[->] (paramsK.south) -- (recombine);
  \draw[->] (recombine.east) -- (recombine -| N) -- (N);
  \draw[->] (N) -- (perturb -| N) -- (perturb); 
  \draw[->] (recombine.south) -- (mysouth -| recombine.south) -- (mysouth -| M) -- (M);
 \draw[->] (M) -- (initialize -| M) -- (initialize);
\end{tikzpicture}

\end{center}
\caption{A flow diagram for an iterated block particle filter. The inner loop is a block particle filter and the outer loop enables parameter estimation.} \label{fig:ibpf}
\end{figure}

\vspace{3mm}

\noindent {\it Likelihood evaluation and maximization}.
The log-likelihood for the SpatPOMP models was calculated using BPF.
This log-likelihood was then maximized using an iterated block particle filter (IBPF) \citep{ionides22,ning23}.
A diagram representing the IBPF algorithm is shown in Figure~\ref{fig:ibpf}.
The inner loop, $n=1,\dots,N$, corresponds to BPF applied to an extension of the model where parameters are perturbed by random noise, allowing the resampling step to provide Darwinian natural selection among the population of particles which favors parameter values consistent with the data.
The outer loop, $m=1,\dots,M$, iterates this BPF procedure while decreasing the magnitude of the perturbations, which is theoretically guaranteed to guide the parameters toward a neighborhood of the maximum likelihood estimate \citep{ionides15,ning23}.
Further discussion of BPF and IBPF is in Supplementary Sec.~{\suppSecIBPF}.
Using this maximization procedure, we constructed confidence intervals by profile likelihood, employing Monte Carlo adjusted profiles \cite{ionides17,ning21} to correct for Monte Carlo variability.


\vspace{3mm}

\noindent {\it Model criticism}.
A negative binomial autoregressive model was used to provide a non-mechanistic benchmark log-likelihood, as described in Supplementary Sec.~\suppSecBenchmark.
This model was also used to construct benchmark conditional log-likelihoods for each separate observation.
These, differenced from the corresponding SEAIR log-likelihoods, were used to define anomalies.
The anomalies were explored to identify data points which were poorly explained by the model (Supplementary Sec.~\suppSecResiduals).
In preliminary data analysis, these anomalies helped to identify some errors in the data which were subsequently corrected (Supplementary Sec.~\suppSecLiModel).

\vspace{3mm}

\noindent {\it Software environment}.
Numerical work was carried out in R \cite{R}. 
Models and data analysis methodology were developed in an R package, \code{metapoppkg}, which is additionally designed to assist reproducibility and extendability of our results.
Models in \code{metapoppkg} are implemented using \code{spatPomp} \cite{asfaw23arxiv} which provides a general representation of SpatPOMP models extending the POMP model representation in \code{pomp} \cite{king16}.

\section*{Data and code availability}
The \code{metapoppkg} R package, containing the data and software used for this article, is available at \url{https://github.com:jifanli/metapoppkg} and archived at \url{https://zenodo.org/records/10149233}.
The manuscript source code is available at \url{https://github.com:jifanli/metapop_article} and archived at \url{https://zenodo.org/records/10149258}.
This source code depends on the \code{metapoppkg} R package and other open-source software archived at \url{https://cran.r-project.org/}.

\section*{Acknowledgements}
This work was supported by National Science Foundation grants DMS-1761603 and DMS-1761612.
Portions of this research were conducted with Texas A\&M High Performance Research Computing and University of Michigan Advanced Research Computing.
We acknowledge discussions with Ethan Romero-Severson and Bryan Grenfell.

\arxiv{}{
\section*{Author contributions}
J.L., E.L.I. and N.N. designed the study and carried out the numerical analysis. J.L., E.L.I, A.A.K. and N.N. developed the software environment supporting the data analysis. All authors discussed and interpreted the results. E.L.I. drafted the manuscript, and all authors edited the manuscript.
}

\bibliographystyle{ieeetr}

\bibliography{bib-metapop}
%\input{ms.bbl}

\end{document}




















